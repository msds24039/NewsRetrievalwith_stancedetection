{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4114bbb-7d4f-445c-a3e4-07f450026025",
   "metadata": {},
   "source": [
    "News retrieval with stance detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "316760bc-7876-4697-8b38-ed449b73278c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up NLTK resources and loading data...\n",
      "Training Word2Vec Skip-gram model...\n",
      "Vectorization complete.\n",
      "Building the BM25 index on unique bodies...\n",
      "BM25 index built.\n",
      "Extracting X_hybrid (202 features)...\n",
      "Training LTR Ranker (XGBoost) with correct grouping...\n",
      "LTR Ranker Training Complete.\n",
      "SVM Classifier Training Complete.\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import xgboost as xgb\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.svm import SVC # Included for consistency, though only LTR is used for ranking\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- 0. Dependency Installation & Setup ---\n",
    "try:\n",
    "    print(\"Setting up NLTK resources and loading data...\")\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "    nltk.download('omw-1.4', quiet=True)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Load FNC-1 Dataset\n",
    "    bodies_df = pd.read_csv(\"train_bodies.csv\")\n",
    "    stances_df = pd.read_csv(\"train_stances.csv\")\n",
    "\n",
    "    # 1. Deduplication (CRITICAL FIX)\n",
    "    bodies_df = bodies_df.drop_duplicates(subset=['articleBody'], keep='first').reset_index(drop=True)\n",
    "    \n",
    "    # 2. Merge data for context (full stance pairs)\n",
    "    data = pd.merge(stances_df, bodies_df, on='Body ID', how='left')\n",
    "    data.dropna(subset=['articleBody'], inplace=True) \n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"\\nFATAL ERROR: Ensure 'train_bodies.csv' and 'train_stances.csv' are in the script directory.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error during setup: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- Preprocessing Function ---\n",
    "def preprocess(text):\n",
    "    \"\"\"Clean, tokenize, remove stop words, and lemmatize text.\"\"\"\n",
    "    if pd.isna(text) or text is None:\n",
    "        return []\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', str(text).lower())\n",
    "    tokens = text.split()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing\n",
    "data['processed_headline'] = data['Headline'].apply(preprocess)\n",
    "data['processed_body'] = data['articleBody'].apply(preprocess)\n",
    "corpus = data['processed_headline'].tolist() + data['processed_body'].tolist()\n",
    "\n",
    "\n",
    "# --- 1. Train Word2Vec and Vectorize (Features for LTR) ---\n",
    "print(\"Training Word2Vec Skip-gram model...\")\n",
    "w2v_model = Word2Vec(sentences=corpus, vector_size=100, window=5, min_count=2, sg=1, negative=5, workers=4)\n",
    "\n",
    "def get_doc_vector(tokens):\n",
    "    vectors = [w2v_model.wv[word] for word in tokens if word in w2v_model.wv]\n",
    "    return np.mean(vectors, axis=0) if len(vectors) > 0 else np.zeros(100)\n",
    "\n",
    "body_vectors = np.array([get_doc_vector(tokens) for tokens in data['processed_body']])\n",
    "headline_vectors = np.array([get_doc_vector(tokens) for tokens in data['processed_headline']])\n",
    "print(\"Vectorization complete.\")\n",
    "\n",
    "\n",
    "# --- 2. Train BM25 Model (Phase 1 Retriever & Feature) ---\n",
    "print(\"Building the BM25 index on unique bodies...\")\n",
    "corpus_tokens_unique = bodies_df['articleBody'].apply(preprocess).tolist()\n",
    "bm25_model = BM25Okapi(corpus_tokens_unique)\n",
    "print(\"BM25 index built.\")\n",
    "\n",
    "def get_single_bm25_score(bm25_model, q_tokens, b_tokens):\n",
    "    # Calculate the score for a query against a single document\n",
    "    try:\n",
    "        temp_bm25 = BM25Okapi([b_tokens])\n",
    "        return temp_bm25.get_scores(q_tokens)[0]\n",
    "    except ZeroDivisionError:\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "# --- 3. Feature Extraction (X_hybrid) ---\n",
    "def extract_hybrid_features(headline_vecs, body_vecs, headline_tokens, body_tokens, bm25_model):\n",
    "    \"\"\"Generates the 202-dimensional feature matrix.\"\"\"\n",
    "    cos_sims = [cosine_similarity(h.reshape(1, -1), b.reshape(1, -1))[0][0] \n",
    "                for h, b in zip(headline_vecs, body_vecs)]\n",
    "    \n",
    "    # Calculate BM25 score for every headline-body pair (Heavy step)\n",
    "    bm25_scores = [get_single_bm25_score(bm25_model, h_tokens, b_tokens) \n",
    "                   for h_tokens, b_tokens in zip(headline_tokens, body_tokens)]\n",
    "\n",
    "    # [H_vec(100), B_vec(100), CosSim(1), BM25(1)] = 202 features\n",
    "    X_hybrid = np.hstack([\n",
    "        headline_vecs, \n",
    "        body_vecs, \n",
    "        np.array(cos_sims).reshape(-1, 1), \n",
    "        np.array(bm25_scores).reshape(-1, 1)\n",
    "    ])\n",
    "    return X_hybrid\n",
    "\n",
    "print(\"Extracting X_hybrid (202 features)...\")\n",
    "X_hybrid = extract_hybrid_features(\n",
    "    headline_vectors, \n",
    "    body_vectors, \n",
    "    data['processed_headline'].tolist(), \n",
    "    data['processed_body'].tolist(),\n",
    "    bm25_model\n",
    ")\n",
    "\n",
    "\n",
    "# --- 4. LTR Training (SelectKBest & XGBRanker) ---\n",
    "print(\"Training LTR Ranker (XGBoost) with correct grouping...\")\n",
    "K_FEATURES = 150\n",
    "relevance_map = {'agree': 3, 'disagree': 3, 'discuss': 2, 'unrelated': 0}\n",
    "\n",
    "# 1. Split data, including the 'Headline' column for grouping\n",
    "X_train_hybrid, _, y_train_stance, _, train_headlines, _ = train_test_split(\n",
    "    X_hybrid,\n",
    "    data['Stance'],\n",
    "    data['Headline'], \n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Feature Selection\n",
    "selector = SelectKBest(k=K_FEATURES)\n",
    "# We must fit the selector on the training data first\n",
    "selector.fit(X_train_hybrid, pd.Series(y_train_stance).map(relevance_map)) \n",
    "X_train_selected = selector.transform(X_train_hybrid)\n",
    "\n",
    "# 3. Create Relevance Labels\n",
    "y_train_rel = np.array([relevance_map[label] for label in y_train_stance])\n",
    "\n",
    "# 4. CRITICAL FIX: Create the Group Information for LTR\n",
    "# Sort training data by Headline to group queries and create the group list\n",
    "train_df = pd.DataFrame({\n",
    "    'features_index': range(len(X_train_selected)),\n",
    "    'Headline': train_headlines.reset_index(drop=True)\n",
    "})\n",
    "train_df = train_df.sort_values(by='Headline').reset_index(drop=True)\n",
    "\n",
    "# Reorder features and labels based on the sorted index\n",
    "X_train_selected_sorted = X_train_selected[train_df['features_index'].values]\n",
    "y_train_rel_sorted = y_train_rel[train_df['features_index'].values]\n",
    "\n",
    "# Count the number of documents (rows) for each unique headline (group)\n",
    "groups_train = train_df.groupby('Headline').size().tolist()\n",
    "\n",
    "# 5. Train XGBoost Ranker\n",
    "ranker = xgb.XGBRanker(objective='rank:pairwise', learning_rate=0.1, n_estimators=100)\n",
    "ranker.fit(X_train_selected_sorted, y_train_rel_sorted, group=groups_train) \n",
    "print(\"LTR Ranker Training Complete.\")\n",
    "\n",
    "# 6. Train SVM Classifier (Required for Stance Prediction)\n",
    "svm_clf = SVC(kernel='linear', C=1.0, random_state=42, probability=True, class_weight='balanced')\n",
    "svm_clf.fit(X_train_selected, y_train_stance)\n",
    "print(\"SVM Classifier Training Complete.\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# ====================================================================\n",
    "# --- INTERACTIVE SEARCH EXECUTION (Phase 1: BM25, Phase 2: LTR/SVM) ---\n",
    "# ====================================================================\n",
    "\n",
    "def two_phase_hybrid_search3():\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"  FINAL HYBRID SYSTEM: BM25 (Phase 1) + LTR/SVM (Phase 2)\")\n",
    "    print(\"  Results are ranked by LTR Score (Hybrid Relevance).\")\n",
    "    print(\"  Type 'exit' or 'quit' to stop.\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"\\n>> Enter Headline Claim: \")\n",
    "        \n",
    "        if user_query.lower() in ['exit', 'quit']:\n",
    "            print(\"Exiting system. Goodbye!\")\n",
    "            break\n",
    "        if not user_query.strip():\n",
    "            continue\n",
    "\n",
    "        q_tokens = preprocess(user_query)\n",
    "        q_vec = get_doc_vector(q_tokens).astype('float32')\n",
    "\n",
    "        # --- PHASE 1: LEXICAL RETRIEVAL (BM25) ---\n",
    "        CANDIDATE_POOL_SIZE = 50 \n",
    "        bm25_all_scores = bm25_model.get_scores(q_tokens)\n",
    "        bm25_indices = np.argsort(bm25_all_scores)[::-1][:CANDIDATE_POOL_SIZE]\n",
    "\n",
    "        if len(bm25_indices) == 0 or bm25_all_scores[bm25_indices[0]] < 0.1:\n",
    "            print(\"   [!] No relevant documents found.\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"--- Phase 1: Retrieved {len(bm25_indices)} candidates via BM25.\")\n",
    "        \n",
    "        # --- FEATURE ALIGNMENT FIX ---\n",
    "        # Find the vector of the closest *training headline* to the query vector \n",
    "        # to ensure features align with SVM/LTR training.\n",
    "        headline_similarities = cosine_similarity(q_vec.reshape(1, -1), headline_vectors)[0]\n",
    "        closest_headline_idx = np.argmax(headline_similarities)\n",
    "        \n",
    "        best_h_vec = headline_vectors[closest_headline_idx]\n",
    "        best_h_text = data.iloc[closest_headline_idx]['Headline']\n",
    "        \n",
    "        print(f\"   [Classifier Reference] Using closest training headline: '{best_h_text}'\")\n",
    "        \n",
    "        # --- PHASE 2: HYBRID RANKING & CLASSIFICATION (LTR/SVM) ---\n",
    "        \n",
    "        candidate_bodies = []\n",
    "        candidate_features = [] # Stores 202-dim vector\n",
    "\n",
    "        # A. Feature Extraction\n",
    "        for idx in bm25_indices:\n",
    "            # Get body information from the unique bodies_df\n",
    "            body_id = bodies_df.loc[idx, 'Body ID']\n",
    "            body_row_full = data[data['Body ID'] == body_id].iloc[0]\n",
    "\n",
    "            b_vec = get_doc_vector(body_row_full['processed_body'])\n",
    "            body_text = body_row_full['articleBody']\n",
    "            b_tokens = body_row_full['processed_body'] \n",
    "            \n",
    "            # Generate Hybrid Feature Vector using the Reference Headline Vector\n",
    "            cos_sim = cosine_similarity(best_h_vec.reshape(1, -1), b_vec.reshape(1, -1))[0][0]\n",
    "            bm25_score = bm25_all_scores[idx] \n",
    "            \n",
    "            feat = np.concatenate([best_h_vec, b_vec, [cos_sim], [bm25_score]])\n",
    "            \n",
    "            candidate_features.append(feat)\n",
    "            candidate_bodies.append(body_text)\n",
    "\n",
    "        candidate_features = np.array(candidate_features)\n",
    "        \n",
    "        # B. Feature Selection\n",
    "        candidate_features_selected = selector.transform(candidate_features)\n",
    "            \n",
    "        # C. Stance Classification (SVM)\n",
    "        predicted_stances = svm_clf.predict(candidate_features_selected)\n",
    "        \n",
    "        # D. Hybrid Re-Ranking (LTR)\n",
    "        ranking_scores = ranker.predict(candidate_features_selected)\n",
    "        \n",
    "        # E. Combine and Sort Results (Sorted by LTR Score)\n",
    "        results = zip(ranking_scores, predicted_stances, candidate_bodies)\n",
    "        sorted_results = sorted(results, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # --- Display Results ---\n",
    "        \n",
    "        print(\"\\n--- Phase 2: Hybrid Re-ranked Results (Sorted by LTR Score) ---\")\n",
    "        print(f\"   Showing top 5 of {len(sorted_results)} results:\\n\")\n",
    "        \n",
    "        for i, (score, stance, body) in enumerate(sorted_results[:5]):\n",
    "            snippet = \" \".join(body.split()[:40]) + \"...\"\n",
    "            stance_display = f\"[{stance.upper()}]\"\n",
    "            \n",
    "            print(f\"   {i+1}. {stance_display} (LTR Score: {score:.4f})\")\n",
    "            print(f\"      Evidence: \\\"{snippet}\\\"\")\n",
    "            print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "705f5f9b-feb8-4e63-b19d-9d0f57299cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  FINAL HYBRID SYSTEM: BM25 (Phase 1) + LTR/SVM (Phase 2)\n",
      "  Results are ranked by LTR Score (Hybrid Relevance).\n",
      "  Type 'exit' or 'quit' to stop.\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Enter Headline Claim:  NASA discover the crater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Retrieved 50 candidates via BM25.\n",
      "   [Classifier Reference] Using closest training headline: 'NASA Raises Doubts About Reports of Nicaraguan Meteorite'\n",
      "\n",
      "--- Phase 2: Hybrid Re-ranked Results (Sorted by LTR Score) ---\n",
      "   Showing top 5 of 50 results:\n",
      "\n",
      "   1. [UNRELATED] (LTR Score: 3.2557)\n",
      "      Evidence: \"We reported on Monday that a meteor, thought possibly to be a chunk of an Earth-passing asteroid, was the cause of a 40-foot crater outside the international airport in the Nicaraguan capital. But astronomers and NASA scientists are now casting...\"\n",
      "--------------------------------------------------\n",
      "   2. [UNRELATED] (LTR Score: 3.1037)\n",
      "      Evidence: \"An explosion and a crater reported near the capital of Nicaragua raised suspicions on Monday that a meteorite had split off from an asteroid that passed by Earth this weekend and struck our planet. But NASA scientists have now cast...\"\n",
      "--------------------------------------------------\n",
      "   3. [UNRELATED] (LTR Score: 3.0165)\n",
      "      Evidence: \"No one was hurt A small meteorite struck a wooded area near the Nicaraguan capital‚Äôs airport on Saturday night. Residents reported hearing a loud bang, and the crater left by the meteorite measured 40-feet wide and 16-feet, BBC reports. No...\"\n",
      "--------------------------------------------------\n",
      "   4. [UNRELATED] (LTR Score: 2.9708)\n",
      "      Evidence: \"A blast near the Nicaraguan capital city of Managua on Saturday night was most likely caused by a meteorite plummeting to Earth, creating a 40-foot-wide crater. A piece of the 2014 RC asteroid that passed close to Earth on Sunday,...\"\n",
      "--------------------------------------------------\n",
      "   5. [UNRELATED] (LTR Score: 2.8856)\n",
      "      Evidence: \"Updated at 11:45 p.m. ET There was an unexpected crash landing near the international airport in the Nicaraguan capital over the weekend, but luckily no one was hurt: A small meteor, thought to have broken off from an Earth-passing asteroid,...\"\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Enter Headline Claim:  NASA questions the crater\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Retrieved 50 candidates via BM25.\n",
      "   [Classifier Reference] Using closest training headline: 'Nasa questions whether crater in Nicaragua caused by meteorite'\n",
      "\n",
      "--- Phase 2: Hybrid Re-ranked Results (Sorted by LTR Score) ---\n",
      "   Showing top 5 of 50 results:\n",
      "\n",
      "   1. [UNRELATED] (LTR Score: 3.2360)\n",
      "      Evidence: \"We reported on Monday that a meteor, thought possibly to be a chunk of an Earth-passing asteroid, was the cause of a 40-foot crater outside the international airport in the Nicaraguan capital. But astronomers and NASA scientists are now casting...\"\n",
      "--------------------------------------------------\n",
      "   2. [UNRELATED] (LTR Score: 3.1898)\n",
      "      Evidence: \"An explosion and a crater reported near the capital of Nicaragua raised suspicions on Monday that a meteorite had split off from an asteroid that passed by Earth this weekend and struck our planet. But NASA scientists have now cast...\"\n",
      "--------------------------------------------------\n",
      "   3. [DISAGREE] (LTR Score: 3.0315)\n",
      "      Evidence: \"No one was hurt A small meteorite struck a wooded area near the Nicaraguan capital‚Äôs airport on Saturday night. Residents reported hearing a loud bang, and the crater left by the meteorite measured 40-feet wide and 16-feet, BBC reports. No...\"\n",
      "--------------------------------------------------\n",
      "   4. [UNRELATED] (LTR Score: 2.9576)\n",
      "      Evidence: \"A blast near the Nicaraguan capital city of Managua on Saturday night was most likely caused by a meteorite plummeting to Earth, creating a 40-foot-wide crater. A piece of the 2014 RC asteroid that passed close to Earth on Sunday,...\"\n",
      "--------------------------------------------------\n",
      "   5. [UNRELATED] (LTR Score: 2.8856)\n",
      "      Evidence: \"Updated at 11:45 p.m. ET There was an unexpected crash landing near the international airport in the Nicaraguan capital over the weekend, but luckily no one was hurt: A small meteor, thought to have broken off from an Earth-passing asteroid,...\"\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Enter Headline Claim:  bunch of students set college on fire\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Retrieved 50 candidates via BM25.\n",
      "   [Classifier Reference] Using closest training headline: 'Student accidentally sets college on fire during fireworks proposal'\n",
      "\n",
      "--- Phase 2: Hybrid Re-ranked Results (Sorted by LTR Score) ---\n",
      "   Showing top 5 of 50 results:\n",
      "\n",
      "   1. [UNRELATED] (LTR Score: 1.6485)\n",
      "      Evidence: \"THIS is definitely NOT how to propose to your girlfriend. A hopeless romantic determined to see his proposal go off with a bang ended up burning down his entire college sports hall with a box of fireworks - bought to...\"\n",
      "--------------------------------------------------\n",
      "   2. [UNRELATED] (LTR Score: 1.5331)\n",
      "      Evidence: \"The proposal went off with a different kind of bang than Dim Xiong Chien had expected when his fireworks set the college ablaze A blundering Romeo who wanted to propose to his girlfriend with a big bang burnt down his...\"\n",
      "--------------------------------------------------\n",
      "   3. [UNRELATED] (LTR Score: 1.4232)\n",
      "      Evidence: \"He popped the question ‚Äî and burned down his college sports hall. Hopeless romantic Dim Xiong Chien planned to propose to his girlfriend, Cong Yen, in explosive fashion by setting off fireworks as he got down on one knee. His...\"\n",
      "--------------------------------------------------\n",
      "   4. [UNRELATED] (LTR Score: 1.0809)\n",
      "      Evidence: \"CHILPANCINGO, Mexico (AP) ‚Äî Authorities testing remains found in nine mass graves in southern Mexico have yet to find any of 43 teachers college students who disappeared after a confrontation with police, security officials said Tuesday. None were among 28...\"\n",
      "--------------------------------------------------\n",
      "   5. [UNRELATED] (LTR Score: 0.8399)\n",
      "      Evidence: \"Dim Xiong Chien is a 22-year-old college student studying at the Liaoning Advertisement Vocational College in the city of Shenyang in northeastern China. According to reports, earlier this week Chien organized a surprise proposal with fireworks for his girlfriend Cong...\"\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Enter Headline Claim:  students set college on fire\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Retrieved 50 candidates via BM25.\n",
      "   [Classifier Reference] Using closest training headline: 'Student accidentally sets college on fire during fireworks proposal'\n",
      "\n",
      "--- Phase 2: Hybrid Re-ranked Results (Sorted by LTR Score) ---\n",
      "   Showing top 5 of 50 results:\n",
      "\n",
      "   1. [UNRELATED] (LTR Score: 1.6485)\n",
      "      Evidence: \"THIS is definitely NOT how to propose to your girlfriend. A hopeless romantic determined to see his proposal go off with a bang ended up burning down his entire college sports hall with a box of fireworks - bought to...\"\n",
      "--------------------------------------------------\n",
      "   2. [UNRELATED] (LTR Score: 1.5331)\n",
      "      Evidence: \"The proposal went off with a different kind of bang than Dim Xiong Chien had expected when his fireworks set the college ablaze A blundering Romeo who wanted to propose to his girlfriend with a big bang burnt down his...\"\n",
      "--------------------------------------------------\n",
      "   3. [UNRELATED] (LTR Score: 1.4232)\n",
      "      Evidence: \"He popped the question ‚Äî and burned down his college sports hall. Hopeless romantic Dim Xiong Chien planned to propose to his girlfriend, Cong Yen, in explosive fashion by setting off fireworks as he got down on one knee. His...\"\n",
      "--------------------------------------------------\n",
      "   4. [UNRELATED] (LTR Score: 1.0809)\n",
      "      Evidence: \"CHILPANCINGO, Mexico (AP) ‚Äî Authorities testing remains found in nine mass graves in southern Mexico have yet to find any of 43 teachers college students who disappeared after a confrontation with police, security officials said Tuesday. None were among 28...\"\n",
      "--------------------------------------------------\n",
      "   5. [UNRELATED] (LTR Score: 0.8399)\n",
      "      Evidence: \"Dim Xiong Chien is a 22-year-old college student studying at the Liaoning Advertisement Vocational College in the city of Shenyang in northeastern China. According to reports, earlier this week Chien organized a surprise proposal with fireworks for his girlfriend Cong...\"\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Enter Headline Claim:  student set college on fire accidentally\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Retrieved 50 candidates via BM25.\n",
      "   [Classifier Reference] Using closest training headline: 'Student accidentally sets college on fire during fireworks proposal'\n",
      "\n",
      "--- Phase 2: Hybrid Re-ranked Results (Sorted by LTR Score) ---\n",
      "   Showing top 5 of 50 results:\n",
      "\n",
      "   1. [UNRELATED] (LTR Score: 1.6485)\n",
      "      Evidence: \"THIS is definitely NOT how to propose to your girlfriend. A hopeless romantic determined to see his proposal go off with a bang ended up burning down his entire college sports hall with a box of fireworks - bought to...\"\n",
      "--------------------------------------------------\n",
      "   2. [UNRELATED] (LTR Score: 1.5331)\n",
      "      Evidence: \"The proposal went off with a different kind of bang than Dim Xiong Chien had expected when his fireworks set the college ablaze A blundering Romeo who wanted to propose to his girlfriend with a big bang burnt down his...\"\n",
      "--------------------------------------------------\n",
      "   3. [UNRELATED] (LTR Score: 1.4232)\n",
      "      Evidence: \"He popped the question ‚Äî and burned down his college sports hall. Hopeless romantic Dim Xiong Chien planned to propose to his girlfriend, Cong Yen, in explosive fashion by setting off fireworks as he got down on one knee. His...\"\n",
      "--------------------------------------------------\n",
      "   4. [UNRELATED] (LTR Score: 1.0809)\n",
      "      Evidence: \"CHILPANCINGO, Mexico (AP) ‚Äî Authorities testing remains found in nine mass graves in southern Mexico have yet to find any of 43 teachers college students who disappeared after a confrontation with police, security officials said Tuesday. None were among 28...\"\n",
      "--------------------------------------------------\n",
      "   5. [UNRELATED] (LTR Score: 0.8399)\n",
      "      Evidence: \"Dim Xiong Chien is a 22-year-old college student studying at the Liaoning Advertisement Vocational College in the city of Shenyang in northeastern China. According to reports, earlier this week Chien organized a surprise proposal with fireworks for his girlfriend Cong...\"\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Enter Headline Claim:  Student accidentally sets college on fire during fireworks proposal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Retrieved 50 candidates via BM25.\n",
      "   [Classifier Reference] Using closest training headline: 'Student accidentally sets college on fire during fireworks proposal'\n",
      "\n",
      "--- Phase 2: Hybrid Re-ranked Results (Sorted by LTR Score) ---\n",
      "   Showing top 5 of 50 results:\n",
      "\n",
      "   1. [UNRELATED] (LTR Score: 1.6485)\n",
      "      Evidence: \"THIS is definitely NOT how to propose to your girlfriend. A hopeless romantic determined to see his proposal go off with a bang ended up burning down his entire college sports hall with a box of fireworks - bought to...\"\n",
      "--------------------------------------------------\n",
      "   2. [UNRELATED] (LTR Score: 1.5331)\n",
      "      Evidence: \"The proposal went off with a different kind of bang than Dim Xiong Chien had expected when his fireworks set the college ablaze A blundering Romeo who wanted to propose to his girlfriend with a big bang burnt down his...\"\n",
      "--------------------------------------------------\n",
      "   3. [UNRELATED] (LTR Score: 1.4232)\n",
      "      Evidence: \"He popped the question ‚Äî and burned down his college sports hall. Hopeless romantic Dim Xiong Chien planned to propose to his girlfriend, Cong Yen, in explosive fashion by setting off fireworks as he got down on one knee. His...\"\n",
      "--------------------------------------------------\n",
      "   4. [UNRELATED] (LTR Score: 1.0809)\n",
      "      Evidence: \"CHILPANCINGO, Mexico (AP) ‚Äî Authorities testing remains found in nine mass graves in southern Mexico have yet to find any of 43 teachers college students who disappeared after a confrontation with police, security officials said Tuesday. None were among 28...\"\n",
      "--------------------------------------------------\n",
      "   5. [UNRELATED] (LTR Score: 0.8399)\n",
      "      Evidence: \"Dim Xiong Chien is a 22-year-old college student studying at the Liaoning Advertisement Vocational College in the city of Shenyang in northeastern China. According to reports, earlier this week Chien organized a surprise proposal with fireworks for his girlfriend Cong...\"\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Enter Headline Claim:  flooding the dam\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Retrieved 50 candidates via BM25.\n",
      "   [Classifier Reference] Using closest training headline: 'Palestine accuses Israel of opening dams, flooding Gaza, forcing evacuations'\n",
      "\n",
      "--- Phase 2: Hybrid Re-ranked Results (Sorted by LTR Score) ---\n",
      "   Showing top 5 of 50 results:\n",
      "\n",
      "   1. [UNRELATED] (LTR Score: 2.0704)\n",
      "      Evidence: \"GAZA, Feb. 22 (Xinhua) -- A Palestinian minister lashed out at Israel on Sunday after it opened its dams near the border with the Gaza Strip, flooding the central area of the besieged enclave with huge amounts of water. Mufid...\"\n",
      "--------------------------------------------------\n",
      "   2. [UNRELATED] (LTR Score: 1.7848)\n",
      "      Evidence: \"Israel has rejected allegations by government officials in the Gaza strip that authorities were responsible for released storm waters flooding parts of the besieged area. \"The claim is entirely false, and southern Israel does not have any dams,\" said a...\"\n",
      "--------------------------------------------------\n",
      "   3. [UNRELATED] (LTR Score: 1.4773)\n",
      "      Evidence: \"Hundreds of Palestinians were evacuated from their homes Sunday morning after Israeli authorities opened a number of dams near the border, flooding the Gaza Valley in the wake of a recent severe winter storm. The Gaza Ministry of Interior said...\"\n",
      "--------------------------------------------------\n",
      "   4. [UNRELATED] (LTR Score: 1.4773)\n",
      "      Evidence: \"GAZA CITY (Ma'an) -- Hundreds of Palestinians were evacuated from their homes Sunday morning after Israeli authorities opened a number of dams near the border, flooding the Gaza Valley in the wake of a recent severe winter storm. The Gaza...\"\n",
      "--------------------------------------------------\n",
      "   5. [UNRELATED] (LTR Score: 1.1249)\n",
      "      Evidence: \"Palestinian officials say hundreds of Gazans were forced to evacuate after Israel opened the gates of several dams on the border with the Gaza Strip, and flooded at least 80 households. Israel has denied the claim as ‚Äúentirely false.‚Äù In...\"\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Enter Headline Claim:  nasa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Retrieved 50 candidates via BM25.\n",
      "   [Classifier Reference] Using closest training headline: 'NASA Raises Doubts About Reports of Nicaraguan Meteorite'\n",
      "\n",
      "--- Phase 2: Hybrid Re-ranked Results (Sorted by LTR Score) ---\n",
      "   Showing top 5 of 50 results:\n",
      "\n",
      "   1. [UNRELATED] (LTR Score: 3.2557)\n",
      "      Evidence: \"We reported on Monday that a meteor, thought possibly to be a chunk of an Earth-passing asteroid, was the cause of a 40-foot crater outside the international airport in the Nicaraguan capital. But astronomers and NASA scientists are now casting...\"\n",
      "--------------------------------------------------\n",
      "   2. [UNRELATED] (LTR Score: 3.1037)\n",
      "      Evidence: \"An explosion and a crater reported near the capital of Nicaragua raised suspicions on Monday that a meteorite had split off from an asteroid that passed by Earth this weekend and struck our planet. But NASA scientists have now cast...\"\n",
      "--------------------------------------------------\n",
      "   3. [DISAGREE] (LTR Score: 2.9708)\n",
      "      Evidence: \"A blast near the Nicaraguan capital city of Managua on Saturday night was most likely caused by a meteorite plummeting to Earth, creating a 40-foot-wide crater. A piece of the 2014 RC asteroid that passed close to Earth on Sunday,...\"\n",
      "--------------------------------------------------\n",
      "   4. [AGREE] (LTR Score: 2.8856)\n",
      "      Evidence: \"Updated at 11:45 p.m. ET There was an unexpected crash landing near the international airport in the Nicaraguan capital over the weekend, but luckily no one was hurt: A small meteor, thought to have broken off from an Earth-passing asteroid,...\"\n",
      "--------------------------------------------------\n",
      "   5. [AGREE] (LTR Score: 2.7587)\n",
      "      Evidence: \"A meteorite landed \"like a bomb\" just missing Nicaragua's main airport and raising concerns over scientists' ability to track space objects on potential collision courses with Earth. Officials said they \"thanked God\" there were no injuries as the rock landed...\"\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Enter Headline Claim:  meteor landing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Retrieved 50 candidates via BM25.\n",
      "   [Classifier Reference] Using closest training headline: 'Meteor Leaves 40-Foot Crater Near Managua's Airport'\n",
      "\n",
      "--- Phase 2: Hybrid Re-ranked Results (Sorted by LTR Score) ---\n",
      "   Showing top 5 of 50 results:\n",
      "\n",
      "   1. [UNRELATED] (LTR Score: 3.1015)\n",
      "      Evidence: \"We reported on Monday that a meteor, thought possibly to be a chunk of an Earth-passing asteroid, was the cause of a 40-foot crater outside the international airport in the Nicaraguan capital. But astronomers and NASA scientists are now casting...\"\n",
      "--------------------------------------------------\n",
      "   2. [UNRELATED] (LTR Score: 2.9497)\n",
      "      Evidence: \"Updated at 11:45 p.m. ET There was an unexpected crash landing near the international airport in the Nicaraguan capital over the weekend, but luckily no one was hurt: A small meteor, thought to have broken off from an Earth-passing asteroid,...\"\n",
      "--------------------------------------------------\n",
      "   3. [UNRELATED] (LTR Score: 2.8725)\n",
      "      Evidence: \"An explosion and a crater reported near the capital of Nicaragua raised suspicions on Monday that a meteorite had split off from an asteroid that passed by Earth this weekend and struck our planet. But NASA scientists have now cast...\"\n",
      "--------------------------------------------------\n",
      "   4. [AGREE] (LTR Score: 2.8046)\n",
      "      Evidence: \"A meteorite landed \"like a bomb\" just missing Nicaragua's main airport and raising concerns over scientists' ability to track space objects on potential collision courses with Earth. Officials said they \"thanked God\" there were no injuries as the rock landed...\"\n",
      "--------------------------------------------------\n",
      "   5. [UNRELATED] (LTR Score: 2.6696)\n",
      "      Evidence: \"(Update: The story has been updated to reflect new evidence and analysis from experts.) News has been circulating about a potential meteorite strike near Managua, Nicaragua late Saturday night, just 13 hours or so before the close flyby of 20-m...\"\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Enter Headline Claim:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting system. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Run the interactive loop\n",
    "two_phase_hybrid_search3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "71bd8a94-4a96-44a1-bf25-60cac5fe9668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "  FINAL HYBRID SYSTEM: BM25 (Phase 1) + LTR/SVM (Phase 2)\n",
      "  Results are ranked by LTR Score (Hybrid Relevance).\n",
      "  Type 'exit' or 'quit' to stop.\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Enter Headline Claim:  gaza\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Phase 1: Retrieved 50 candidates via BM25.\n",
      "   [Classifier Reference] Using closest training headline: 'Israel opens dams, floods Gaza'\n",
      "\n",
      "--- Phase 2: Hybrid Re-ranked Results (Sorted by LTR Score) ---\n",
      "   Showing top 5 of 50 results:\n",
      "\n",
      "   1. [UNRELATED] (LTR Score: 2.5377)\n",
      "      Evidence: \"GAZA, Feb. 22 (Xinhua) -- A Palestinian minister lashed out at Israel on Sunday after it opened its dams near the border with the Gaza Strip, flooding the central area of the besieged enclave with huge amounts of water. Mufid...\"\n",
      "--------------------------------------------------\n",
      "   2. [UNRELATED] (LTR Score: 2.2695)\n",
      "      Evidence: \"GAZA CITY (Ma'an) -- Hundreds of Palestinians were evacuated from their homes Sunday morning after Israeli authorities opened a number of dams near the border, flooding the Gaza Valley in the wake of a recent severe winter storm. The Gaza...\"\n",
      "--------------------------------------------------\n",
      "   3. [UNRELATED] (LTR Score: 2.0983)\n",
      "      Evidence: \"Hundreds of Palestinians were evacuated from their homes Sunday morning after Israeli authorities opened a number of dams near the border, flooding the Gaza Valley in the wake of a recent severe winter storm. The Gaza Ministry of Interior said...\"\n",
      "--------------------------------------------------\n",
      "   4. [UNRELATED] (LTR Score: 1.6110)\n",
      "      Evidence: \"Israel has rejected allegations by government officials in the Gaza strip that authorities were responsible for released storm waters flooding parts of the besieged area. \"The claim is entirely false, and southern Israel does not have any dams,\" said a...\"\n",
      "--------------------------------------------------\n",
      "   5. [UNRELATED] (LTR Score: 1.3831)\n",
      "      Evidence: \"Palestinian officials say hundreds of Gazans were forced to evacuate after Israel opened the gates of several dams on the border with the Gaza Strip, and flooded at least 80 households. Israel has denied the claim as ‚Äúentirely false.‚Äù In...\"\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      ">> Enter Headline Claim:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exiting system. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# Run the interactive loop\n",
    "two_phase_hybrid_search3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b54dac72-74dc-48ee-90a6-c5ea727aeb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Evaluation: Predicting Scores on Test Set ---\n",
      "\n",
      "==================================================\n",
      "¬† ¬† ¬† ¬† ¬† ¬† ¬†üîç SYSTEM EVALUATION üìä\n",
      "==================================================\n",
      "Total Test Queries Evaluated: 1572\n",
      "--------------------------------------------------\n",
      "--- LTR RANKING METRICS ---\n",
      "Mean Average Precision (MAP): 0.9989\n",
      "Normalized Discounted Cumulative Gain (NDCG): 0.9977\n",
      "--------------------------------------------------\n",
      "--- SVM CLASSIFICATION METRICS ---\n",
      "Overall Accuracy: 0.9047\n",
      "\n",
      "Classification Report (Precision/Recall/F1-score):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       agree       0.56      0.60      0.58       734\n",
      "    disagree       0.29      0.83      0.43       170\n",
      "     discuss       0.84      0.72      0.78      1763\n",
      "   unrelated       1.00      0.98      0.99      7255\n",
      "\n",
      "    accuracy                           0.90      9922\n",
      "   macro avg       0.67      0.78      0.69      9922\n",
      "weighted avg       0.93      0.90      0.91      9922\n",
      "\n",
      "\n",
      "Confusion Matrix (Rows=True Label, Columns=Predicted Label):\n",
      "\n",
      "           Pred agree  Pred disagree  Pred discuss  Pred unrelated\n",
      "agree             441            139           148               6\n",
      "disagree           14            141            15               0\n",
      "discuss           291            184          1274              14\n",
      "unrelated          40             20            75            7120\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score, classification_report, accuracy_score, confusion_matrix\n",
    "from collections import defaultdict\n",
    "\n",
    "# --- 1. Re-split Data to Get Test Set ---\n",
    "# We assume X_hybrid, data['Stance'], and data['Headline'] are loaded from your main script\n",
    "# Use the same random_state=42 to guarantee the exact same split as training.\n",
    "_, X_test_hybrid, _, y_test_stance, _, test_headlines = train_test_split(\n",
    "    X_hybrid,\n",
    "    data['Stance'],\n",
    "    data['Headline'],\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2. Map Stance Labels to Relevance Grades (0-3)\n",
    "relevance_map = {'agree': 3, 'disagree': 3, 'discuss': 2, 'unrelated': 0}\n",
    "y_test_rel = np.array([relevance_map[label] for label in y_test_stance])\n",
    "\n",
    "\n",
    "# --- 2. Predict Relevance Scores on Test Set (Phase 2) ---\n",
    "print(\"\\n--- Starting Evaluation: Predicting Scores on Test Set ---\")\n",
    "\n",
    "# Apply the trained SelectKBest feature selection\n",
    "X_test_selected = selector.transform(X_test_hybrid)\n",
    "\n",
    "# Use the LTR Ranker to predict the relevance score for every test pair\n",
    "predicted_scores = ranker.predict(X_test_selected)\n",
    "\n",
    "\n",
    "# --- 3. Group Metrics by Headline (Query) ---\n",
    "\n",
    "# Re-create a DataFrame for the test set to facilitate grouping by headline\n",
    "test_df = pd.DataFrame({\n",
    "    'headline': test_headlines.reset_index(drop=True),\n",
    "    'score': predicted_scores,\n",
    "    'true_rel': y_test_rel\n",
    "})\n",
    "\n",
    "# Dictionary to hold the true relevance grades and predicted scores for each unique query (headline)\n",
    "query_metrics = defaultdict(lambda: {'true': [], 'score': []})\n",
    "for _, row in test_df.iterrows():\n",
    "    query_metrics[row['headline']]['true'].append(row['true_rel'])\n",
    "    query_metrics[row['headline']]['score'].append(row['score'])\n",
    "\n",
    "\n",
    "# --- 4. Define Evaluation Metrics ---\n",
    "\n",
    "def calculate_ndcg(true_grades, predicted_scores):\n",
    "    \"\"\"Calculates NDCG@k. We use k=None (all results) for simplicity.\"\"\"\n",
    "    \n",
    "    # Sort true grades based on predicted scores\n",
    "    relevance = np.array(true_grades)[np.argsort(predicted_scores)[::-1]]\n",
    "    \n",
    "    # Calculate DCG\n",
    "    # DCG formula: sum( (2^rel - 1) / log2(i + 1) )\n",
    "    discount = np.log2(np.arange(len(relevance)) + 2) # i starts at 0, discount starts at log2(2)\n",
    "    dcg = np.sum((np.power(2, relevance) - 1) / discount)\n",
    "\n",
    "    # Calculate IDCG (Ideal DCG)\n",
    "    ideal_relevance = np.sort(relevance)[::-1]\n",
    "    idcg = np.sum((np.power(2, ideal_relevance) - 1) / discount)\n",
    "    \n",
    "    return dcg / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def calculate_map(true_grades, predicted_scores):\n",
    "    \"\"\"Calculates Average Precision (AP) for a single query.\"\"\"\n",
    "    # MAP requires binary relevance (rel > 0 is relevant)\n",
    "    true_binary = (np.array(true_grades) > 0).astype(int)\n",
    "    \n",
    "    # average_precision_score requires sorting by the score\n",
    "    return average_precision_score(true_binary, predicted_scores)\n",
    "\n",
    "\n",
    "# --- 5. Calculate Overall Metrics ---\n",
    "\n",
    "map_scores = []\n",
    "ndcg_scores = []\n",
    "total_queries = len(query_metrics)\n",
    "\n",
    "for query, metrics in query_metrics.items():\n",
    "    # Only evaluate queries with at least one relevant document for non-zero AP\n",
    "    if np.sum(metrics['true']) > 0:\n",
    "        map_scores.append(calculate_map(metrics['true'], metrics['score']))\n",
    "        ndcg_scores.append(calculate_ndcg(metrics['true'], metrics['score']))\n",
    "\n",
    "\n",
    "final_map = np.mean(map_scores)\n",
    "final_ndcg = np.mean(ndcg_scores)\n",
    "\n",
    "# --- 5.5. Calculate SVM Classification Metrics ---\n",
    "\n",
    "# 1. Predict Stance Labels on the Test Set\n",
    "# We use the trained svm_clf and the same selected test features X_test_selected\n",
    "predicted_stances = svm_clf.predict(X_test_selected)\n",
    "\n",
    "# 2. Get True Stance Labels\n",
    "# y_test_stance holds the true categorical labels ('agree', 'unrelated', etc.)\n",
    "true_stances = y_test_stance.reset_index(drop=True)\n",
    "\n",
    "# 3. Calculate Overall Accuracy\n",
    "svm_accuracy = accuracy_score(true_stances, predicted_stances)\n",
    "\n",
    "# 4. Generate Detailed Report (Precision, Recall, F1-score for each class)\n",
    "# classification_report generates a comprehensive text summary.\n",
    "svm_classification_report = classification_report(true_stances, predicted_stances, zero_division=0)\n",
    "\n",
    "# 5. Generate Confusion Matrix (Optional, but highly informative)\n",
    "# The labels list ensures the matrix is ordered consistently.\n",
    "labels_order = ['agree', 'disagree', 'discuss', 'unrelated']\n",
    "conf_matrix = confusion_matrix(true_stances, predicted_stances, labels=labels_order)\n",
    "\n",
    "# Convert confusion matrix to a readable format (e.g., a DataFrame)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=labels_order, columns=[f'Pred {l}' for l in labels_order])\n",
    "\n",
    "\n",
    "# --- 6. Display Results (Updated) ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"¬† ¬† ¬† ¬† ¬† ¬† ¬†üîç SYSTEM EVALUATION üìä\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total Test Queries Evaluated: {total_queries}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "## LTR RANKING METRICS\n",
    "print(\"--- LTR RANKING METRICS ---\")\n",
    "print(f\"Mean Average Precision (MAP): {final_map:.4f}\")\n",
    "print(f\"Normalized Discounted Cumulative Gain (NDCG): {final_ndcg:.4f}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "## SVM CLASSIFICATION METRICS\n",
    "print(\"--- SVM CLASSIFICATION METRICS ---\")\n",
    "print(f\"Overall Accuracy: {svm_accuracy:.4f}\\n\")\n",
    "print(\"Classification Report (Precision/Recall/F1-score):\\n\")\n",
    "print(svm_classification_report)\n",
    "print(\"\\nConfusion Matrix (Rows=True Label, Columns=Predicted Label):\\n\")\n",
    "print(conf_matrix_df)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595a07fb-cbf1-4750-9621-99885d637897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "37d88b31-f2f4-4ecc-a43c-d39d10e9403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Launching Gradio Interface...\n",
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# --- NOTE: REPLICATE THE run_hybrid_search FUNCTION FOR GRADIO ---\n",
    "# We must use a dedicated function that returns a string (Markdown) for Gradio output.\n",
    "def run_hybrid_search_for_gradio(user_query: str) -> str:\n",
    "    \"\"\"Adapts the two_phase_hybrid_search logic to return a formatted string for Gradio.\"\"\"\n",
    "    global bm25_model, w2v_model, selector, ranker, svm_clf, data, bodies_df, headline_vectors\n",
    "    \n",
    "    # Quick checks for initialization (useful if not all setup was run)\n",
    "    if not all([bm25_model, w2v_model, selector, ranker, svm_clf]):\n",
    "        return \"System not fully initialized. Please ensure all training steps ran successfully.\"\n",
    "    if not user_query.strip():\n",
    "        return \"Please enter a headline claim.\"\n",
    "\n",
    "    q_tokens = preprocess(user_query)\n",
    "    q_vec = get_doc_vector(q_tokens).astype('float32')\n",
    "\n",
    "    # --- PHASE 1: LEXICAL RETRIEVAL (BM25) ---\n",
    "    CANDIDATE_POOL_SIZE = 50 \n",
    "    bm25_all_scores = bm25_model.get_scores(q_tokens)\n",
    "    bm25_indices = np.argsort(bm25_all_scores)[::-1][:CANDIDATE_POOL_SIZE]\n",
    "\n",
    "    if len(bm25_indices) == 0 or (len(bm25_all_scores) > 0 and bm25_all_scores[bm25_indices[0]] < 0.1):\n",
    "        return \"No strongly relevant documents found via BM25.\"\n",
    "        \n",
    "    # --- FEATURE ALIGNMENT FIX (Using closest training headline vector) ---\n",
    "    headline_similarities = cosine_similarity(q_vec.reshape(1, -1), headline_vectors)[0]\n",
    "    closest_headline_idx = np.argmax(headline_similarities)\n",
    "    best_h_vec = headline_vectors[closest_headline_idx]\n",
    "    best_h_text = data.iloc[closest_headline_idx]['Headline']\n",
    "\n",
    "    # --- PHASE 2: HYBRID RANKING & CLASSIFICATION (LTR/SVM) ---\n",
    "    candidate_features = []\n",
    "    candidate_bodies = []\n",
    "\n",
    "    for idx in bm25_indices:\n",
    "        body_id = bodies_df.loc[idx, 'Body ID']\n",
    "        # Locate the body's full row in the *merged* data frame for vector access\n",
    "        body_row_full = data[data['Body ID'] == body_id].iloc[0] \n",
    "\n",
    "        b_vec = get_doc_vector(body_row_full['processed_body'])\n",
    "        body_text = body_row_full['articleBody']\n",
    "        \n",
    "        # Feature vector generation\n",
    "        cos_sim = cosine_similarity(best_h_vec.reshape(1, -1), b_vec.reshape(1, -1))[0][0]\n",
    "        bm25_score = bm25_all_scores[idx] \n",
    "        feat = np.concatenate([best_h_vec, b_vec, [cos_sim], [bm25_score]])\n",
    "        \n",
    "        candidate_features.append(feat)\n",
    "        candidate_bodies.append(body_text)\n",
    "\n",
    "    candidate_features = np.array(candidate_features)\n",
    "    \n",
    "    # Prediction\n",
    "    candidate_features_selected = selector.transform(candidate_features)\n",
    "    predicted_stances = svm_clf.predict(candidate_features_selected)\n",
    "    ranking_scores = ranker.predict(candidate_features_selected)\n",
    "    \n",
    "    # Combine and Sort Results\n",
    "    results = zip(ranking_scores, predicted_stances, candidate_bodies)\n",
    "    sorted_results = sorted(results, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "    # --- Format Output for Gradio (Markdown) ---\n",
    "    output_markdown = f\"## üîé Hybrid Search Results\\n\"\n",
    "    output_markdown += f\"--- Phase 1: Retrieved {len(bm25_indices)} candidates via BM25 ---\\n\\n\"\n",
    "    output_markdown += f\"**Classifier Reference Headline:** '{best_h_text}'\\n\\n\"\n",
    "    output_markdown += f\"--- Phase 2: Ranked by LTR Score (Top 5 of {len(sorted_results)}) ---\\n\\n\"\n",
    "\n",
    "    for i, (score, stance, body) in enumerate(sorted_results[:5]):\n",
    "        snippet = \" \".join(body.split()[:50]) + \"...\"\n",
    "        stance_display = f\"**[{stance.upper()}]**\"\n",
    "        \n",
    "        output_markdown += f\"### {i+1}. {stance_display} (LTR Score: {score:.4f})\\n\"\n",
    "        output_markdown += f\"> Evidence: \\\"{snippet}\\\"\\n\\n\"\n",
    "        output_markdown += f\"---\\n\"\n",
    "        \n",
    "    return output_markdown.strip()\n",
    "\n",
    "\n",
    "# Define the Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=run_hybrid_search_for_gradio, \n",
    "    \n",
    "    inputs=gr.Textbox(\n",
    "        lines=2, \n",
    "        placeholder=\"Enter a query of Headline claim \", \n",
    "        label=\"Headline Claim\"\n",
    "    ),\n",
    "    \n",
    "    outputs=gr.Markdown(label=\"Hybrid IR System Output\"),\n",
    "    \n",
    "    title=\"News Retrieval system with stance detection\",\n",
    "    description=\"Query the trained two-phase system (BM25 Retrieval, LTR Ranking & SVM classification).\",\n",
    "    # theme=\"soft\",\n",
    "    # allow_flagging=\"never\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "print(\"\\nLaunching Gradio Interface...\")\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
